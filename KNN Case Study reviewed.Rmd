---
title: "Assigment - kNN DIY"
author:
  - Luc Heimans - Author
  - Daan Plass - Reviewer
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
   html_notebook:
    toc: true
    toc_depth: 2
---

# setup

```{r message=FALSE, warning=FALSE}

library(ggplot2)
library(caret)
```


```{r message=FALSE, warning=FALSE}
library(class)
library(tidyverse)
library(googlesheets4)
library(class)
```

```{r}
Rawd_review <- read.csv("https://raw.githubusercontent.com/HAN-M3DM-Data-Mining/assignments/master/datasets/KNN-occupancy.csv")
```

## Business Understanding
The business case in this instance is to experiment with the KNN machine learning methodology, following the CRISP DM model. The goal is to, as accurately as possible, predict the value of a label, based on KNN learning. In this case I will try to classify the value of the label; occupancy as accurately as possible, using KNN methodology.

## Data Understanding
In this step I will explore the data set to become familiar with the data and understand its structure.

What becomes clear is that I will be dealing with structured data. Furthermore, occupancy consists of integer values. Data consists of characters and the remaining variables are numerical.

```{r}
str(Rawd_review)
head(Rawd_review)
```

Since the label is occupancy in this case, I would like to also explore the relationships between outcomes.

```{r}
cntRawd_review <- table(Rawd_review$Occupancy)
propRawd_review <- round(prop.table(cntRawd_review)*100, digits = 1)
print(cntRawd_review)
print(propRawd_review)
```

What becomes clear is that occupancy with a value of 0 is 79% more common than a value of 1.

## Data Preparation

In this step I will clean the data to remain with values that are of value to classifying new data.
The variable 'date' is not of relevance in creating a model which should predict the label; occupancy, and thus will be removed from the dataset.

```{r}
cleand_review <- Rawd_review[-1]
head(cleand_review)
```

I will also search for possible N/A values:

```{r}
indx_review <- apply(cleand_review, 2, function(cleand_review) any(is.na(cleand_review)))
colnames(indx_review)
```

Colnames command answers "NULL", meaning there are no values in any of the columns which consist of N/A.


###Turning the variable "Occupancy" into a factor because the model requires this instead of a variable classified as a factor. 

```{r}
cleand_review$Occupancy <- factor(cleand_review$Occupancy, levels = c("1", "0"), labels = c("Yes", "No")) %>% relevel("Yes")
head(cleand_review, 10)
```

### Making a summary to have a closer look at different variables to define the ranges 


```{r}
summary(cleand_review[c("Temperature", "Humidity", "Light","CO2", "HumidityRatio")])
```

 The range of between different variables is very different this could potentially cause problems for modeling 
 because e.g. CO2 will have a larger impact on the distance calculation than the Temperature 
 
### Creating a function that will normailize the range, so eliminating the big differences in range to provent modeling problems.
This function will turn values into a percentage of the maximum. 

```{r}
normalize <- function(x) {return ((x - min(x)) / (max(x) - min(x)))}

testSet1 <- c(1:6)
testSet2 <- c(1:6) * 10

cat("testSet1:", testSet1, "\n")
cat("testSet2:", testSet2, "\n")

cat("Normalized testSet1:", normalize(testSet1), "\n")
cat("Normalized testSet2:", normalize(testSet2))
```


 
 
### Normalizing the range of all variables except "Occupancy", so eliminating the big differences in range to prevent modeling problems. 

```{r}
nCols <- dim(cleand_review)[6]
cleand_review_n <- sapply(1:5,
                    function(x) {
  normalize(cleand_review[,x])
}) %>% as.data.frame()

names(cleand_review_n) <- c("Temperature", "Humidity", "Light","CO2", "HumidityRatio")


summary(cleand_review_n[c("Temperature", "Humidity", "Light","CO2", "HumidityRatio")])
```



To eliminate biases and overfitting of the algorithm (Freecodecamp, 2020), data is splitted into two sets; a training and test set.

```{r}
train_df_review <- cleand_review_n[1:7000,]
testd_df_review <- cleand_review_n[7000:8143,]
train_label_review <- cleand_review[1:7000, 6]
test_label_review <- cleand_review[7000:8143, 6]
```

###changing the data set from "cleand_review" to "cleand_review_n" for both "train_df_review" and "testd_df_review" 





## Modeling

I will change the names used for describing the data set related vectors (rawd, cleand, testd etc.) to 'occupancy', since this was the original name of the data set.

The code for generating the knn model:

```{r}
Occupancy_pred_review <- knn(train = as.matrix(train_df_review), test = as.matrix(testd_df_review), cl = as.matrix(train_label_review), k= 89) 
head(Occupancy_pred_review)
```

### I added train = as.matrix, test = as.matrix, cl = as.matrix and added brackets to train_df_review, testd_df_review, train_label_review


## Evaluation and Deployment
The model is created, and will be evaluated by running the prediction against the test data set, using the confusionmatrix command.

```{r}
#confusionMatrix(table(Occupancy_pred_review, test_label_review)) 

confusionMatrix(Occupancy_pred_review, test_label_review)
```


## reviewer adds suggestions for improving the model

Use ### to indicate a change you made to this review document.

References
https://datasharkie.com/how-to-normalize-data-in-r/
https://www.freecodecamp.org/news/key-machine-learning-concepts-explained-dataset-splitting-and-random-forest/
https://towardsdatascience.com/decoding-the-confusion-matrix-bb4801decbb